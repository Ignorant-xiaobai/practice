{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑斯蒂回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Author:Dodo\n",
    "# Date:2018-11-27\n",
    "# Email:lvtengchao@pku.edu.cn\n",
    "# Blog:www.pkudodo.com\n",
    "\n",
    "'''\n",
    "数据集：Mnist\n",
    "训练集数量：60000\n",
    "测试集数量：10000\n",
    "------------------------------\n",
    "运行结果：\n",
    "    正确率：98.91%\n",
    "    运行时长：59s\n",
    "'''\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def loadData(fileName):\n",
    "    '''\n",
    "    加载Mnist数据集\n",
    "    :param fileName:要加载的数据集路径\n",
    "    :return: list形式的数据集及标记\n",
    "    '''\n",
    "    # 存放数据及标记的list\n",
    "    dataList = []; labelList = []\n",
    "    # 打开文件\n",
    "    fr = open(fileName, 'r')\n",
    "    # 将文件按行读取\n",
    "    for line in fr.readlines():\n",
    "        # 对每一行数据按切割福','进行切割，返回字段列表\n",
    "        curLine = line.strip().split(',')\n",
    "\n",
    "        # Mnsit有0-9是个标记，由于是二分类任务，所以将标记0的作为1，其余为0\n",
    "        # 验证过<5为1 >5为0时正确率在90%左右，猜测是因为数多了以后，可能不同数的特征较乱，不能有效地计算出一个合理的超平面\n",
    "        # 查看了一下之前感知机的结果，以5为分界时正确率81，重新修改为0和其余数时正确率98.91%\n",
    "        # 看来如果样本标签比较杂的话，对于是否能有效地划分超平面确实存在很大影响\n",
    "        if int(curLine[0]) == 0:\n",
    "            labelList.append(1)\n",
    "        else:\n",
    "            labelList.append(0)\n",
    "        #存放标记\n",
    "        #[int(num) for num in curLine[1:]] -> 遍历每一行中除了以第一哥元素（标记）外将所有元素转换成int类型\n",
    "        #[int(num)/255 for num in curLine[1:]] -> 将所有数据除255归一化(非必须步骤，可以不归一化)\n",
    "        dataList.append([int(num)/255 for num in curLine[1:]])\n",
    "        # dataList.append([int(num) for num in curLine[1:]])\n",
    "\n",
    "    #返回data和label\n",
    "    return dataList, labelList\n",
    "\n",
    "def predict(w, x):\n",
    "    '''\n",
    "    预测标签\n",
    "    :param w:训练过程中学到的w\n",
    "    :param x: 要预测的样本\n",
    "    :return: 预测结果\n",
    "    '''\n",
    "    #dot为两个向量的点积操作，计算得到w * x\n",
    "    wx = np.dot(w, x)\n",
    "    #计算标签为1的概率\n",
    "    #该公式参考“6.1.2 二项逻辑斯蒂回归模型”中的式6.5\n",
    "    P1 = np.exp(wx) / (1 + np.exp(wx))\n",
    "    #如果为1的概率大于0.5，返回1\n",
    "    if P1 >= 0.5:\n",
    "        return 1\n",
    "    #否则返回0\n",
    "    return 0\n",
    "\n",
    "def logisticRegression(trainDataList, trainLabelList, iter = 200):\n",
    "    '''\n",
    "    逻辑斯蒂回归训练过程\n",
    "    :param trainDataList:训练集\n",
    "    :param trainLabelList: 标签集\n",
    "    :param iter: 迭代次数\n",
    "    :return: 习得的w\n",
    "    '''\n",
    "    #按照书本“6.1.2 二项逻辑斯蒂回归模型”中式6.5的规则，将w与b合在一起，\n",
    "    #此时x也需要添加一维，数值为1\n",
    "    #循环遍历每一个样本，并在其最后添加一个1\n",
    "    for i in range(len(trainDataList)):\n",
    "        trainDataList[i].append(1)\n",
    "\n",
    "    #将数据集由列表转换为数组形式，主要是后期涉及到向量的运算，统一转换成数组形式比较方便\n",
    "    trainDataList = np.array(trainDataList)\n",
    "    #初始化w，维数为样本x维数+1，+1的那一位是b，初始为0\n",
    "    w = np.zeros(trainDataList.shape[1])\n",
    "\n",
    "    #设置步长\n",
    "    h = 0.001\n",
    "\n",
    "    #迭代iter次进行随机梯度下降\n",
    "    for i in range(iter):\n",
    "        #每次迭代冲遍历一次所有样本，进行随机梯度下降\n",
    "        for j in range(trainDataList.shape[0]):\n",
    "            #随机梯度上升部分\n",
    "            #在“6.1.3 模型参数估计”一章中给出了似然函数，我们需要极大化似然函数\n",
    "            #但是似然函数由于有求和项，并不能直接对w求导得出最优w，所以针对似然函数求和\n",
    "            #部分中每一项进行单独地求导w，得到针对该样本的梯度，并进行梯度上升（因为是\n",
    "            #要求似然函数的极大值，所以是梯度上升，如果是极小值就梯度下降。梯度上升是\n",
    "            #加号，下降是减号）\n",
    "            #求和式中每一项单独对w求导结果为：xi * yi - (exp(w * xi) * xi) / (1 + exp(w * xi))\n",
    "            #如果对于该求导式有疑问可查看我的博客 www.pkudodo.com\n",
    "\n",
    "            #计算w * xi，因为后式中要计算两次该值，为了节约时间这里提前算出\n",
    "            #其实也可直接算出exp(wx)，为了读者能看得方便一点就这么写了，包括yi和xi都提前列出了\n",
    "            wx = np.dot(w, trainDataList[j])\n",
    "            yi = trainLabelList[j]\n",
    "            xi = trainDataList[j]\n",
    "            #梯度上升\n",
    "            w +=  h * (xi * yi - (np.exp(wx) * xi) / ( 1 + np.exp(wx)))\n",
    "\n",
    "    #返回学到的w\n",
    "    return w\n",
    "\n",
    "def model_test(testDataList, testLabelList, w):\n",
    "    '''\n",
    "    验证\n",
    "    :param testDataList:测试集\n",
    "    :param testLabelList: 测试集标签\n",
    "    :param w: 训练过程中学到的w\n",
    "    :return: 正确率\n",
    "    '''\n",
    "\n",
    "    #与训练过程一致，先将所有的样本添加一维，值为1，理由请查看训练函数\n",
    "    for i in range(len(testDataList)):\n",
    "        testDataList[i].append(1)\n",
    "\n",
    "    #错误值计数\n",
    "    errorCnt = 0\n",
    "    #对于测试集中每一个测试样本进行验证\n",
    "    for i in range(len(testDataList)):\n",
    "        #如果标记与预测不一致，错误值加1\n",
    "        if testLabelList[i] != predict(w, testDataList[i]):\n",
    "            errorCnt += 1\n",
    "    #返回准确率\n",
    "    return 1 - errorCnt / len(testDataList)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "\n",
    "    # 获取训练集及标签\n",
    "    print('start read transSet')\n",
    "    trainData, trainLabel = loadData('../Mnist/mnist_train.csv')\n",
    "\n",
    "    # 获取测试集及标签\n",
    "    print('start read testSet')\n",
    "    testData, testLabel = loadData('../Mnist/mnist_test.csv')\n",
    "\n",
    "    # 开始训练，学习w\n",
    "    print('start to train')\n",
    "    w = logisticRegression(trainData, trainLabel)\n",
    "\n",
    "    #验证正确率\n",
    "    print('start to test')\n",
    "    accuracy = model_test(testData, testLabel, w)\n",
    "\n",
    "    # 打印准确率\n",
    "    print('the accuracy is:', accuracy)\n",
    "    # 打印时间\n",
    "    print('time span:', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最大熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Author:Dodo\n",
    "# Date:2018-11-30\n",
    "# Email:lvtengchao@pku.edu.cn\n",
    "# Blog:www.pkudodo.com\n",
    "\n",
    "'''\n",
    "数据集：Mnist\n",
    "训练集数量：60000(实际使用:20000)\n",
    "测试集数量：10000\n",
    "------------------------------\n",
    "运行结果：\n",
    "    正确率：96.9%\n",
    "    运行时长：8.8h\n",
    "备注：对于mnist而言，李航的统计学习方法中有一些关键细节没有阐述，\n",
    "建议先阅读我的个人博客，其中有详细阐述。阅读结束后再看该程序。\n",
    "Blog：www.pkudodo.com\n",
    "'''\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def loadData(fileName):\n",
    "    '''\n",
    "    加载Mnist数据集\n",
    "    :param fileName:要加载的数据集路径\n",
    "    :return: list形式的数据集及标记\n",
    "    '''\n",
    "    # 存放数据及标记的list\n",
    "    dataList = []; labelList = []\n",
    "    # 打开文件\n",
    "    fr = open(fileName, 'r')\n",
    "    # 将文件按行读取\n",
    "    for line in fr.readlines():\n",
    "        # 对每一行数据按切割福','进行切割，返回字段列表\n",
    "        curLine = line.strip().split(',')\n",
    "        #二分类，list中放置标签\n",
    "        if int(curLine[0]) == 0:\n",
    "            labelList.append(1)\n",
    "        else:\n",
    "            labelList.append(0)\n",
    "        #二值化\n",
    "        dataList.append([int(int(num) > 128) for num in curLine[1:]])\n",
    "\n",
    "    #返回data和label\n",
    "    return dataList, labelList\n",
    "\n",
    "\n",
    "class maxEnt:\n",
    "    '''\n",
    "    最大熵类\n",
    "    '''\n",
    "    def __init__(self, trainDataList, trainLabelList, testDataList, testLabelList):\n",
    "        '''\n",
    "        各参数初始化\n",
    "        '''\n",
    "        self.trainDataList = trainDataList          #训练数据集\n",
    "        self.trainLabelList = trainLabelList        #训练标签集\n",
    "        self.testDataList = testDataList            #测试数据集\n",
    "        self.testLabelList = testLabelList          #测试标签集\n",
    "        self.featureNum = len(trainDataList[0])     #特征数量\n",
    "\n",
    "        self.N = len(trainDataList)                 #总训练集长度\n",
    "        self.n = 0                                  #训练集中（xi，y）对数量\n",
    "        self.M = 10000                              #\n",
    "        self.fixy = self.calc_fixy()                #所有(x, y)对出现的次数\n",
    "        self.w = [0] * self.n                       #Pw(y|x)中的w\n",
    "        self.xy2idDict, self.id2xyDict = self.createSearchDict()        #(x, y)->id和id->(x, y)的搜索字典\n",
    "        self.Ep_xy = self.calcEp_xy()               #Ep_xy期望值\n",
    "\n",
    "    def calcEpxy(self):\n",
    "        '''\n",
    "        计算特征函数f(x, y)关于模型P(Y|X)与经验分布P_(X, Y)的期望值（P后带下划线“_”表示P上方的横线\n",
    "        程序中部分下划线表示“|”，部分表示上方横线，请根据具体公式自行判断,）\n",
    "        即“6.2.2 最大熵模型的定义”中第二个期望（83页最上方的期望）\n",
    "        :return:\n",
    "        '''\n",
    "        #初始化期望存放列表，对于每一个xy对都有一个期望\n",
    "        #这里的x是单个的特征，不是一个样本的全部特征。例如x={x1，x2，x3.....，xk}，实际上是（x1，y），（x2，y），。。。\n",
    "        #但是在存放过程中需要将不同特诊的分开存放，李航的书可能是为了公式的泛化性高一点，所以没有对这部分提及\n",
    "        #具体可以看我的博客，里面有详细介绍  www.pkudodo.com\n",
    "        Epxy = [0] * self.n\n",
    "        #对于每一个样本进行遍历\n",
    "        for i in range(self.N):\n",
    "            #初始化公式中的P(y|x)列表\n",
    "            Pwxy = [0] * 2\n",
    "            #计算P(y = 0 } X)\n",
    "            #注：程序中X表示是一个样本的全部特征，x表示单个特征，这里是全部特征的一个样本\n",
    "            Pwxy[0] = self.calcPwy_x(self.trainDataList[i], 0)\n",
    "            #计算P(y = 1 } X)\n",
    "            Pwxy[1] = self.calcPwy_x(self.trainDataList[i], 1)\n",
    "\n",
    "            for feature in range(self.featureNum):\n",
    "                for y in range(2):\n",
    "                    if (self.trainDataList[i][feature], y) in self.fixy[feature]:\n",
    "                        id = self.xy2idDict[feature][(self.trainDataList[i][feature], y)]\n",
    "                        Epxy[id] += (1 / self.N) * Pwxy[y]\n",
    "        return Epxy\n",
    "\n",
    "    def calcEp_xy(self):\n",
    "        '''\n",
    "        计算特征函数f(x, y)关于经验分布P_(x, y)的期望值（下划线表示P上方的横线，\n",
    "        同理Ep_xy中的“_”也表示p上方的横线）\n",
    "        即“6.2.2 最大熵的定义”中第一个期望（82页最下方那个式子）\n",
    "        :return: 计算得到的Ep_xy\n",
    "        '''\n",
    "        #初始化Ep_xy列表，长度为n\n",
    "        Ep_xy = [0] * self.n\n",
    "\n",
    "        #遍历每一个特征\n",
    "        for feature in range(self.featureNum):\n",
    "            #遍历每个特征中的(x, y)对\n",
    "            for (x, y) in self.fixy[feature]:\n",
    "                #获得其id\n",
    "                id = self.xy2idDict[feature][(x, y)]\n",
    "                #将计算得到的Ep_xy写入对应的位置中\n",
    "                #fixy中存放所有对在训练集中出现过的次数，处于训练集总长度N就是概率了\n",
    "                Ep_xy[id] = self.fixy[feature][(x, y)] / self.N\n",
    "\n",
    "        #返回期望\n",
    "        return Ep_xy\n",
    "\n",
    "    def createSearchDict(self):\n",
    "        '''\n",
    "        创建查询字典\n",
    "        xy2idDict：通过(x,y)对找到其id,所有出现过的xy对都有一个id\n",
    "        id2xyDict：通过id找到对应的(x,y)对\n",
    "        '''\n",
    "        #设置xy搜多id字典\n",
    "        #这里的x指的是单个的特征，而不是某个样本，因此将特征存入字典时也需要存入这是第几个特征\n",
    "        #这一信息，这是为了后续的方便，否则会乱套。\n",
    "        #比如说一个样本X = (0, 1, 1) label =(1)\n",
    "        #生成的标签对有(0, 1), (1, 1), (1, 1)，三个(x，y)对并不能判断属于哪个特征的，后续就没法往下写\n",
    "        #不可能通过(1, 1)就能找到对应的id，因为对于(1, 1),字典中有多重映射\n",
    "        #所以在生成字典的时总共生成了特征数个字典，例如在mnist中样本有784维特征，所以生成784个字典，属于\n",
    "        #不同特征的xy存入不同特征内的字典中，使其不会混淆\n",
    "        xy2idDict = [{} for i in range(self.featureNum)]\n",
    "        #初始化id到xy对的字典。因为id与(x，y)的指向是唯一的，所以可以使用一个字典\n",
    "        id2xyDict = {}\n",
    "\n",
    "        #设置缩影，其实就是最后的id\n",
    "        index = 0\n",
    "        #对特征进行遍历\n",
    "        for feature in range(self.featureNum):\n",
    "            #对出现过的每一个(x, y)对进行遍历\n",
    "            #fixy：内部存放特征数目个字典，对于遍历的每一个特征，单独读取对应字典内的(x, y)对\n",
    "            for (x, y) in self.fixy[feature]:\n",
    "                #将该(x, y)对存入字典中，要注意存入时通过[feature]指定了存入哪个特征内部的字典\n",
    "                #同时将index作为该对的id号\n",
    "                xy2idDict[feature][(x, y)] = index\n",
    "                #同时在id->xy字典中写入id号，val为(x, y)对\n",
    "                id2xyDict[index] = (x, y)\n",
    "                #id加一\n",
    "                index += 1\n",
    "\n",
    "        #返回创建的两个字典\n",
    "        return xy2idDict, id2xyDict\n",
    "\n",
    "\n",
    "    def calc_fixy(self):\n",
    "        '''\n",
    "        计算(x, y)在训练集中出现过的次数\n",
    "        :return:\n",
    "        '''\n",
    "        #建立特征数目个字典，属于不同特征的(x, y)对存入不同的字典中，保证不被混淆\n",
    "        fixyDict = [defaultdict(int) for i in range(self.featureNum)]\n",
    "        #遍历训练集中所有样本\n",
    "        for i in range(len(self.trainDataList)):\n",
    "            #遍历样本中所有特征\n",
    "            for j in range(self.featureNum):\n",
    "                #将出现过的(x, y)对放入字典中并计数值加1\n",
    "                fixyDict[j][(self.trainDataList[i][j], self.trainLabelList[i])] += 1\n",
    "        #对整个大字典进行计数，判断去重后还有多少(x, y)对，写入n\n",
    "        for i in fixyDict:\n",
    "            self.n += len(i)\n",
    "        #返回大字典\n",
    "        return fixyDict\n",
    "\n",
    "\n",
    "    def calcPwy_x(self, X, y):\n",
    "        '''\n",
    "        计算“6.23 最大熵模型的学习” 式6.22\n",
    "        :param X: 要计算的样本X（一个包含全部特征的样本）\n",
    "        :param y: 该样本的标签\n",
    "        :return: 计算得到的Pw(Y|X)\n",
    "        '''\n",
    "        #分子\n",
    "        numerator = 0\n",
    "        #分母\n",
    "        Z = 0\n",
    "        #对每个特征进行遍历\n",
    "        for i in range(self.featureNum):\n",
    "            #如果该(xi,y)对在训练集中出现过\n",
    "            if (X[i], y) in self.xy2idDict[i]:\n",
    "                #在xy->id字典中指定当前特征i，以及(x, y)对：(X[i], y)，读取其id\n",
    "                index = self.xy2idDict[i][(X[i], y)]\n",
    "                #分子是wi和fi(x，y)的连乘再求和，最后指数\n",
    "                #由于当(x, y)存在时fi(x，y)为1，因为xy对肯定存在，所以直接就是1\n",
    "                #对于分子来说，就是n个wi累加，最后再指数就可以了\n",
    "                #因为有n个w，所以通过id将w与xy绑定，前文的两个搜索字典中的id就是用在这里\n",
    "                numerator += self.w[index]\n",
    "            #同时计算其他一种标签y时候的分子，下面的z并不是全部的分母，再加上上式的分子以后\n",
    "            #才是完整的分母，即z = z + numerator\n",
    "            if (X[i], 1-y) in self.xy2idDict[i]:\n",
    "                #原理与上式相同\n",
    "                index = self.xy2idDict[i][(X[i], 1-y)]\n",
    "                Z += self.w[index]\n",
    "        #计算分子的指数\n",
    "        numerator = np.exp(numerator)\n",
    "        #计算分母的z\n",
    "        Z = np.exp(Z) + numerator\n",
    "        #返回Pw(y|x)\n",
    "        return numerator / Z\n",
    "\n",
    "\n",
    "    def maxEntropyTrain(self, iter = 500):\n",
    "        #设置迭代次数寻找最优解\n",
    "        for i in range(iter):\n",
    "            #单次迭代起始时间点\n",
    "            iterStart = time.time()\n",
    "\n",
    "            #计算“6.2.3 最大熵模型的学习”中的第二个期望（83页最上方哪个）\n",
    "            Epxy = self.calcEpxy()\n",
    "\n",
    "            #使用的是IIS，所以设置sigma列表\n",
    "            sigmaList = [0] * self.n\n",
    "            #对于所有的n进行一次遍历\n",
    "            for j in range(self.n):\n",
    "                #依据“6.3.1 改进的迭代尺度法” 式6.34计算\n",
    "                sigmaList[j] = (1 / self.M) * np.log(self.Ep_xy[j] / Epxy[j])\n",
    "\n",
    "            #按照算法6.1步骤二中的（b）更新w\n",
    "            self.w = [self.w[i] + sigmaList[i] for i in range(self.n)]\n",
    "\n",
    "            #单次迭代结束\n",
    "            iterEnd = time.time()\n",
    "            #打印运行时长信息\n",
    "            print('iter:%d:%d, time:%d'%(i, iter, iterStart - iterEnd))\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        预测标签\n",
    "        :param X:要预测的样本\n",
    "        :return: 预测值\n",
    "        '''\n",
    "        #因为y只有0和1，所有建立两个长度的概率列表\n",
    "        result = [0] * 2\n",
    "        #循环计算两个概率\n",
    "        for i in range(2):\n",
    "            #计算样本x的标签为i的概率\n",
    "            result[i] = self.calcPwy_x(X, i)\n",
    "        #返回标签\n",
    "        #max(result)：找到result中最大的那个概率值\n",
    "        #result.index(max(result))：通过最大的那个概率值再找到其索引，索引是0就返回0，1就返回1\n",
    "        return result.index(max(result))\n",
    "\n",
    "    def test(self):\n",
    "        '''\n",
    "        对测试集进行测试\n",
    "        :return:\n",
    "        '''\n",
    "        #错误值计数\n",
    "        errorCnt = 0\n",
    "        #对测试集中所有样本进行遍历\n",
    "        for i in range(len(self.testDataList)):\n",
    "            #预测该样本对应的标签\n",
    "            result = self.predict(self.testDataList[i])\n",
    "            #如果错误，计数值加1\n",
    "            if result != self.testLabelList[i]:   errorCnt += 1\n",
    "        #返回准确率\n",
    "        return 1 - errorCnt / len(self.testDataList)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "\n",
    "    # 获取训练集及标签\n",
    "    print('start read transSet')\n",
    "    trainData, trainLabel = loadData('../Mnist/mnist_train.csv')\n",
    "\n",
    "    # 获取测试集及标签\n",
    "    print('start read testSet')\n",
    "    testData, testLabel = loadData('../Mnist/mnist_test.csv')\n",
    "\n",
    "    #初始化最大熵类\n",
    "    maxEnt = maxEnt(trainData[:20000], trainLabel[:20000], testData, testLabel)\n",
    "\n",
    "    #开始训练\n",
    "    print('start to train')\n",
    "    maxEnt.maxEntropyTrain()\n",
    "\n",
    "    #开始测试\n",
    "    print('start to test')\n",
    "    accuracy = maxEnt.test()\n",
    "    print('the accuracy is:', accuracy)\n",
    "\n",
    "    # 打印时间\n",
    "    print('time span:', time.time() - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
